{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOeJF8O5LY73"
   },
   "source": [
    "# Introduction\n",
    "We assembled thoracic radiotherapy planning CT scans from 150 patients with locally advanced non-small cell lung cancer at Penn Radiation Oncology for primary GTV segmentation. The dataset is not publicly available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_KKQwBOM4AT"
   },
   "source": [
    "## Imports\n",
    "**Task: Import the necessary libraries**\n",
    "\n",
    "* Pathlib for easy path handling\n",
    "* nibabel as the files are provided in the NIfTI format\n",
    "* numpy for data saving and processing\n",
    "* matplotlib for plotting\n",
    "* celluloid for nice volume visualization\n",
    "* tqdm for nice progressing bars\n",
    "* cv2 for resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOtcYTAgJzsz"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from celluloid import Camera\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydkVs1mfNm-5"
   },
   "source": [
    "## Inspection:\n",
    "**Task: Define the paths to images and labels for training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mJBYmaC3PPny",
    "outputId": "106d94e2-7bde-42e2-8bec-06c5d546e923"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "# Base folder shown in your screenshot\n",
    "BASE = Path(\"E:/DoNotTouch/projects/LANSCLC/CIS_5810/selected_150_split\")\n",
    "\n",
    "if not BASE.exists():\n",
    "    raise FileNotFoundError(f\"Path not found: {BASE}\\n\"\n",
    "                            \"Double-check the exact folder names in My Drive.\")\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "def find_niis(root: Path):\n",
    "    # finds both .nii.gz and .nii\n",
    "    return list(root.rglob(\"*.nii.gz\")) + list(root.rglob(\"*.nii\"))\n",
    "\n",
    "for s in splits:\n",
    "    split_dir = BASE / s\n",
    "    nii_paths = find_niis(split_dir)\n",
    "    print(f\"{s}: {len(nii_paths)} files\")\n",
    "    for p in nii_paths[:3]:   # show a few examples\n",
    "        print(\"  \", p)\n",
    "    print()\n",
    "\n",
    "# Optional: pick one file from train to load later\n",
    "train_files = find_niis(BASE / \"train\")\n",
    "if train_files:\n",
    "    sample_path = train_files[0]\n",
    "    print(\"Sample file:\", sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "itebde1EMsf9",
    "outputId": "4dfbd6f6-350b-4959-a0db-00416ac24984"
   },
   "outputs": [],
   "source": [
    "images = list((BASE / \"train\" / \"image\").rglob(\"*.nii.gz\"))\n",
    "labels = list((BASE / \"train\" / \"label_gtvp\").rglob(\"*.nii.gz\"))\n",
    "print(\"train images:\", len(images), \" | train labels:\", len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJkN-P5yXv6g"
   },
   "source": [
    "**Task: Load a sample NIfTI and its corresponding label mask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIuP0eKvSexH"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def change_img_to_label_path(img_path: Path) -> Path:\n",
    "    img_path = Path(img_path)\n",
    "    # swap .../image/... -> .../label_gtvp/...\n",
    "    label_dir = img_path.parent.parent / \"label_gtvp\"\n",
    "    # remove only the FINAL \"_0000\" before extension\n",
    "    new_name = re.sub(r'_0000(?=\\.nii(\\.gz)?$)', '', img_path.name)\n",
    "    return label_dir / new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQ8Jw472X59N"
   },
   "outputs": [],
   "source": [
    "# images: List[Path]\n",
    "candidates = [p for p in images if p.name.startswith(\"Lung\")]\n",
    "if len(candidates) < 3:\n",
    "    raise IndexError(f\"Only {len(candidates)} files match 'Lung*'\")\n",
    "sample_path = candidates[2]   # 3rd match\n",
    "sample_path_label = change_img_to_label_path(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyloI5eVYFNj",
    "outputId": "1819cadb-f12a-4df3-cd21-74b0a2a0360d"
   },
   "outputs": [],
   "source": [
    "sample_path, sample_path_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgPNeiynbyS7"
   },
   "source": [
    "### Load NIfTI and extract image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Z9La3JPYogz"
   },
   "outputs": [],
   "source": [
    "data = nib.load(sample_path)\n",
    "label = nib.load(sample_path_label)\n",
    "\n",
    "ct = data.get_fdata()\n",
    "mask = label.get_fdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oD2I-Z-rb67K"
   },
   "source": [
    "**Task: Find out the orientation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07Chj8KEZLll",
    "outputId": "fe24ed1e-a7fc-4dff-f600-90adceb5c196"
   },
   "outputs": [],
   "source": [
    "nib.aff2axcodes(data.affine) # In Part 2, I mistakenly planned to use RAS; in Part 3, I’ll correct this to LPS. We’ll only convert to RAS if a specific tool requires it (typically some neuroimaging tools)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0D-KblTfjsg"
   },
   "source": [
    "**Task: Inspect the loaded data with overlaid Ground Truth tumor segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "Mcl3FZwgcFgk",
    "outputId": "32c3b974-dd6c-4272-a9b4-8083ad350431"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from celluloid import Camera\n",
    "\n",
    "def reorient(slice2d: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Flip vertically, then rotate -90 degrees.\"\"\"\n",
    "    s = np.flipud(slice2d)      # flip top/bottom\n",
    "    s = np.rot90(s, k=3)        # -90° (clockwise)\n",
    "    return s\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "camera = Camera(fig)\n",
    "\n",
    "for i in range(0, ct.shape[2], 2):  # axial slices\n",
    "    ct_i   = reorient(ct[:, :, i])\n",
    "    mask_i = reorient(mask[:, :, i])\n",
    "\n",
    "    ax.imshow(ct_i, cmap=\"bone\", interpolation=\"nearest\")  # origin default 'upper' is fine after our transform\n",
    "    ax.imshow(np.ma.masked_where(mask_i == 0, mask_i), alpha=0.5,\n",
    "              cmap=\"autumn\", interpolation=\"nearest\")\n",
    "    ax.set_axis_off()\n",
    "    camera.snap()\n",
    "\n",
    "anim = camera.animate(interval=180, blit=True, repeat=True, repeat_delay=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "bL7YYOyufoIb",
    "outputId": "32ca4b55-714c-437a-c144-a171736937bd"
   },
   "outputs": [],
   "source": [
    "# once in the env:\n",
    "# pip install imageio-ffmpeg\n",
    "import matplotlib as mpl, imageio_ffmpeg\n",
    "mpl.rcParams['animation.ffmpeg_path'] = imageio_ffmpeg.get_ffmpeg_exe()\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-k70DHUj6G9"
   },
   "source": [
    "## Preprocessing\n",
    "**Task: Perform the following preprocessing steps:**\n",
    "\n",
    "1. CT images have a fixed range from -1000 to 3071. **Thus we normalize by dividing by 3071** <br /> We don't need to compute mean and standard deviation for this task\n",
    "2. As we want to focus on lung tumors, we can crop away parts of the lower abdomen to reduce the complexity and help the network learn. As an example, **we skip the first 20 slices (from lower abdomen to the neck)** (last axis)\n",
    "3. As we want to tackle this task on a slice level (2D) and not on a subject level (3D) to reduce the computational cost **we store the preprocessed data as 2d files**, because reading a single slice is much faster than loading the complete NIfTI file.\n",
    "4. Resize the single slices and masks to (256, 256) (when resizing the mask, pass interpolation=cv2.INTER_NEAREST to the resize function to apply nearest neighbour interpolation)\n",
    "\n",
    "Loop over all_files and apply the preprocessing steps. <br />\n",
    "\n",
    "In the preprocessing loop, you need to create a directory for each subject containg the ct and label slices with identical names. <br />\n",
    "E.g:\n",
    "* 0/data/0.npy\n",
    "* 0/masks/0.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "7HJVuMCqqJbo",
    "outputId": "3ff00bad-8c0e-43cc-b8b4-1075b1231554"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def collect_pairs(split_dir: Path):\n",
    "    \"\"\"Return (image_path, label_path) pairs for a split; warn if a label is missing.\"\"\"\n",
    "    img_dir = split_dir / \"image\"\n",
    "    img_paths = list(img_dir.rglob(\"*.nii*\"))\n",
    "    pairs = []\n",
    "    for ip in img_paths:\n",
    "        lp = change_img_to_label_path(ip)  # your existing helper\n",
    "        if lp.exists():\n",
    "            pairs.append((ip, lp))\n",
    "        else:\n",
    "            print(f\"WARNING ({split_dir.name}): missing label for {ip.name}\")\n",
    "    return pairs\n",
    "\n",
    "# Existing base\n",
    "# BASE = Path(\"/...\")  # already defined earlier\n",
    "\n",
    "pairs_train = collect_pairs(BASE / \"train\")\n",
    "pairs_val   = collect_pairs(BASE / \"val\")\n",
    "pairs_test  = collect_pairs(BASE / \"test\")   # <-- NEW\n",
    "\n",
    "print(f\"Paired counts -> train: {len(pairs_train)} | val: {len(pairs_val)} | test: {len(pairs_test)}\")\n",
    "\n",
    "# If you want a merged list (train+val+test)\n",
    "pairs_all = pairs_train + pairs_val + pairs_test\n",
    "print(f\"Merged total (train+val+test): {len(pairs_all)}\")\n",
    "\n",
    "# Optional: peek a few from each split\n",
    "for name, pairs in [(\"train\", pairs_train), (\"val\", pairs_val), (\"test\", pairs_test)]:\n",
    "    print(f\"\\n{name} preview:\")\n",
    "    for i, (ip, lp) in enumerate(pairs[:3]):\n",
    "        print(f\"  [{i}] img: {ip.name}  |  lbl: {lp.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "g6OhujwGfrZu",
    "outputId": "64f01865-e742-4693-aa23-222454e69adf"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from fnmatch import fnmatch\n",
    "\n",
    "all_files = [img for (img, lbl) in pairs_all if fnmatch(Path(img).name, \"Lung_*\")]\n",
    "print(len(all_files), \"matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q4s9XNM0l79D",
    "outputId": "f3df8653-6e75-4323-abbe-e57035050e38"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time, shutil\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import zoom  # <-- use SciPy resize, not OpenCV\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "# ====== CONFIG ======\n",
    "# Assumes you already defined:\n",
    "#   BASE: Path to your dataset root (Path)\n",
    "#   all_files: list[Path] of CT NIfTI files\n",
    "#   change_img_to_label_path: function mapping CT path -> label path\n",
    "save_root = BASE / \"Preprocessed_for_2D_Unet\"\n",
    "\n",
    "TRAIN_N = 70   # first 70 -> train\n",
    "VAL_N   = 40   # next 40 -> val\n",
    "# remaining -> test\n",
    "\n",
    "TARGET_HW = (256, 256)  # (H, W)  <-- use H,W convention for SciPy\n",
    "\n",
    "# ====== HELPERS ======\n",
    "def safe_np_save(dest_path: Path, array: np.ndarray, retries: int = 5, sleep: float = 0.5):\n",
    "    \"\"\"Atomic-ish save: write a temp .npy next to the target, then move.\"\"\"\n",
    "    dest_path = dest_path.with_suffix(\".npy\")\n",
    "    dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    tmp_local = dest_path.parent / (dest_path.stem + \".__tmp__.npy\")\n",
    "    np.save(tmp_local, array)\n",
    "\n",
    "    last_err = None\n",
    "    for k in range(retries):\n",
    "        try:\n",
    "            shutil.move(str(tmp_local), str(dest_path))\n",
    "            return\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(sleep * (2 ** k))\n",
    "    raise OSError(f\"Failed to write {dest_path} after {retries} retries\") from last_err\n",
    "\n",
    "def as_img2d(a) -> np.ndarray:\n",
    "    \"\"\"Ensure a clean 2D, C-contiguous float32 base ndarray (no subclasses).\"\"\"\n",
    "    a = np.asarray(a, dtype=np.float32).view(np.ndarray)\n",
    "    a = np.squeeze(a)\n",
    "    if a.ndim != 2:\n",
    "        raise ValueError(f\"Expected 2D slice, got shape {a.shape}\")\n",
    "    if not a.flags[\"C_CONTIGUOUS\"]:\n",
    "        a = np.ascontiguousarray(a)\n",
    "    return a\n",
    "\n",
    "def scipy_resize2d(img2d: np.ndarray, out_hw: Tuple[int, int], order: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Resize 2D with SciPy ndimage.zoom.\n",
    "    - out_hw: (H_out, W_out)\n",
    "    - order: 1 for linear (images), 0 for nearest (masks)\n",
    "    \"\"\"\n",
    "    src = as_img2d(img2d)\n",
    "    H, W = src.shape\n",
    "    Ht, Wt = int(out_hw[0]), int(out_hw[1])\n",
    "    zy = Ht / float(H)\n",
    "    zx = Wt / float(W)\n",
    "    # prefilter=False is fine for order 0/1 and faster\n",
    "    out = zoom(src, (zy, zx), order=order, prefilter=False)\n",
    "    return out.astype(np.float32, copy=False)\n",
    "\n",
    "# ====== MAIN ======\n",
    "save_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "n_train = n_val = n_test = 0\n",
    "\n",
    "for counter, path_to_ct_data in enumerate(tqdm(all_files, desc=\"Preprocessing\")):\n",
    "    path_to_label = change_img_to_label_path(path_to_ct_data)  # may not exist\n",
    "\n",
    "    # --- Load volumes as float32 base ndarray ---\n",
    "    ct_img = nib.load(path_to_ct_data)\n",
    "    ct_vol = np.array(ct_img.get_fdata(dtype=np.float32), dtype=np.float32, copy=False)  # (H,W,D)\n",
    "\n",
    "    has_label = path_to_label.exists()\n",
    "    if has_label:\n",
    "        lbl_img = nib.load(path_to_label)\n",
    "        lbl_vol = np.array(lbl_img.get_fdata(dtype=np.float32), dtype=np.float32, copy=False)\n",
    "\n",
    "    # --- Optional depth crop & basic scaling ---\n",
    "    if ct_vol.shape[-1] > 20:\n",
    "        ct_vol = ct_vol[:, :, 20:]\n",
    "        if has_label:\n",
    "            lbl_vol = lbl_vol[:, :, 20:]\n",
    "\n",
    "    # Scale HU-ish range if raw HU provided (adjust as you like)\n",
    "    ct_vol = ct_vol / 3071.0\n",
    "\n",
    "    # Sanitize numerics\n",
    "    ct_vol = np.nan_to_num(ct_vol, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    if has_label:\n",
    "        lbl_vol = np.nan_to_num(lbl_vol, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Ensure there are slices after crop\n",
    "    D = int(ct_vol.shape[-1])\n",
    "    if D == 0:\n",
    "        print(f\"[Skip] No slices after crop: {path_to_ct_data}\")\n",
    "        continue\n",
    "\n",
    "    # --- Decide split ---\n",
    "    if counter < TRAIN_N:\n",
    "        split = \"train\"; n_train += 1\n",
    "    elif counter < TRAIN_N + VAL_N:\n",
    "        split = \"val\";   n_val += 1\n",
    "    else:\n",
    "        split = \"test\";  n_test += 1\n",
    "\n",
    "    current_path = save_root / split / str(counter)\n",
    "    data_dir = current_path / \"data\"\n",
    "    mask_dir = current_path / \"masks\"\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if has_label:\n",
    "        mask_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- Slice-wise save ---\n",
    "    for i in range(D):\n",
    "        slc = scipy_resize2d(ct_vol[:, :, i], TARGET_HW, order=1)   # linear for images\n",
    "        safe_np_save(data_dir / f\"{i}\", slc)\n",
    "\n",
    "        if has_label:\n",
    "            msk = scipy_resize2d(lbl_vol[:, :, i], TARGET_HW, order=0)  # nearest for masks\n",
    "            safe_np_save(mask_dir / f\"{i}\", msk)\n",
    "\n",
    "print(f\"Saved cases -> train: {n_train} | val: {n_val} | test: {n_test}\")\n",
    "print(\"Output root:\", save_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6mh1s8swV1o"
   },
   "source": [
    "# Validate preprocessed data\n",
    "**Task: Take a look at stored files and inspect if everything worked as expected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "em0XFQeWmTLi"
   },
   "outputs": [],
   "source": [
    "path = BASE / \"Preprocessed_for_2D_Unet/train/2\"  # Select a subject. Check the folder if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EIfZWsH8wyg5",
    "outputId": "ae02cdd7-ab0d-4acd-9cb8-b3e32992fbd1"
   },
   "outputs": [],
   "source": [
    "list(path.glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVZ-LgNhw1BJ"
   },
   "outputs": [],
   "source": [
    "file = \"36.npy\"\n",
    "slice = np.load(path/\"data\"/file)\n",
    "mask = np.load(path/\"masks\"/file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "kF5BaM2dxNkB",
    "outputId": "c4bdbfea-9dca-42dd-dc9c-bd91b00aeb0d"
   },
   "outputs": [],
   "source": [
    "# 1) Ensure inline backend\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def reorient_2d(a: np.ndarray) -> np.ndarray:\n",
    "    return np.rot90(np.flipud(a), k=3)  # flip TB, rotate -90° (clockwise)\n",
    "\n",
    "# slc, msk must be 2D arrays\n",
    "slc = np.asarray(slice)      # your CT slice\n",
    "msk = np.asarray(mask)       # your mask (0/1)\n",
    "\n",
    "# safety checks\n",
    "assert slc.ndim == 2 and msk.ndim == 2, (slc.shape, msk.shape)\n",
    "assert slc.shape == msk.shape, \"slice/mask shapes must match\"\n",
    "\n",
    "# reorient\n",
    "slc_r = reorient_2d(slc)\n",
    "msk_r = reorient_2d(msk)\n",
    "\n",
    "# robust window\n",
    "vmin, vmax = np.percentile(slc_r, [1, 99])\n",
    "if not np.isfinite(vmin) or not np.isfinite(vmax) or vmax <= vmin:\n",
    "    vmin, vmax = float(np.nanmin(slc_r)), float(np.nanmax(slc_r))\n",
    "\n",
    "# 2) Make and show the figure (no global close, no clear_output)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.imshow(slc_r, cmap=\"bone\", vmin=vmin, vmax=vmax)\n",
    "ax.imshow(np.ma.masked_where(msk_r == 0, msk_r), cmap=\"autumn\", alpha=0.5, interpolation=\"nearest\")\n",
    "ax.axis(\"off\")\n",
    "fig.tight_layout()\n",
    "plt.show()            # <-- explicitly show\n",
    "plt.close(fig)        # close just this figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0aWKRLaxetR",
    "outputId": "e40ca1a8-c315-47b3-ffc1-672c98a6be7a"
   },
   "outputs": [],
   "source": [
    "print(slice.min(), slice.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMB5UTnM4JfC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
