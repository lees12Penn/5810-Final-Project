{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ParDzreeGXP7"
   },
   "source": [
    "# Introduction\n",
    "In this notebook, we created the dataset class used to feed slices and corresponding segmentation masks to the network during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1E0y5tjGvOA"
   },
   "source": [
    "## Imports\n",
    "\n",
    "* pathlib for easy path handling\n",
    "* torch for dataset creation\n",
    "* numpy for file loading and processing\n",
    "* imgaug for data augmentation\n",
    "* matplotlib for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6CNddV3U1gcy"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import imgaug\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXmJMgR3Lznh"
   },
   "source": [
    "## DataSet Creation\n",
    "We implemented the following functionality:\n",
    "1. Create a list of all 2D slices. To so we need to extract all slices from all subjects\n",
    "2. Extract the corresponding label path for each slice path\n",
    "3. Load slice and label\n",
    "4. Data Augmentation. Make sure that slice and mask are augmented identically. imgaug handles this for us, thus we will not use torchvision.transforms for that\n",
    "5. Return slice and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CApMgGYQLlDv"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "import numpy as np\n",
    "import imgaug\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "\n",
    "PathLike = Union[str, Path]\n",
    "\n",
    "class LungDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root: PathLike, augment_params=None, base_seed: Optional[int] = None):\n",
    "        root = Path(root)\n",
    "        if not root.exists():\n",
    "            raise FileNotFoundError(f\"Root not found: {root}\")\n",
    "        self.all_files = self.extract_files(root)\n",
    "        self.augment_params = augment_params\n",
    "        self.base_seed = int(base_seed) if base_seed is not None else None\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_files(root: Path) -> list:\n",
    "        files = []\n",
    "        for subject in root.glob(\"*\"):\n",
    "            data_dir = subject / \"data\"\n",
    "            if not data_dir.exists():\n",
    "                continue\n",
    "            for slc in data_dir.glob(\"*\"):\n",
    "                files.append(slc)\n",
    "        return files\n",
    "\n",
    "    @staticmethod\n",
    "    def change_img_to_label_path(path: Path) -> Path:\n",
    "        parts = list(path.parts)\n",
    "        parts[parts.index(\"data\")] = \"masks\"\n",
    "        return Path(*parts)\n",
    "\n",
    "    def augment(self, img2d: np.ndarray, mask2d: np.ndarray):\n",
    "        # imgaug expects integer labels in the segmap\n",
    "        seg = SegmentationMapsOnImage(mask2d.astype(np.uint8, copy=False), shape=img2d.shape)\n",
    "        img_aug, seg_aug = self.augment_params(\n",
    "            image=img2d.astype(np.float32, copy=False),\n",
    "            segmentation_maps=seg\n",
    "        )\n",
    "        mask_aug = seg_aug.get_arr().astype(np.float32, copy=False)  # back to float for loss\n",
    "        return img_aug, mask_aug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_files)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        file_path = self.all_files[idx]\n",
    "        mask_path = self.change_img_to_label_path(file_path)\n",
    "\n",
    "        img  = np.load(file_path).astype(np.float32, copy=False)  # (H,W) float32\n",
    "        mask = np.load(mask_path)                                 # (H,W) int/bool preferred\n",
    "\n",
    "        if self.augment_params:\n",
    "            if self.base_seed is not None:\n",
    "                imgaug.seed(self.base_seed + int(idx))  # reproducible per index\n",
    "            img, mask = self.augment(img, mask)\n",
    "        else:\n",
    "            mask = mask.astype(np.float32, copy=False)\n",
    "\n",
    "        # Return (1,H,W) tensors\n",
    "        img_t  = torch.from_numpy(img).unsqueeze(0)   # float32\n",
    "        mask_t = torch.from_numpy(mask).unsqueeze(0)  # float32\n",
    "        return img_t, mask_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhS4NO2mMD4R"
   },
   "source": [
    "Define the data augmentation routine corresponding of scaling and rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hHTlPIT5L-t3"
   },
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.Affine(scale=(0.85, 1.15), # zoom in or out\n",
    "               rotate=(-45, 45)),  # rotate up to 45 degrees\n",
    "    iaa.ElasticTransformation()\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eQXhXfuxMQBx",
    "outputId": "56db76c4-6f30-456d-e676-2b0f63cec511"
   },
   "outputs": [],
   "source": [
    "# Create the dataset object\n",
    "BASE = Path(\"E:/DoNotTouch/projects/LANSCLC/CIS_5810/selected_150_split\")\n",
    "path = BASE / \"Preprocessed_for_2D_Unet/train\"\n",
    "\n",
    "print(f\"BASE exists? {BASE.exists()} -> {BASE}\")\n",
    "print(f\"path exists? {path.exists()} -> {path}\")\n",
    "\n",
    "# Optional: quick peek at layout\n",
    "if path.exists():\n",
    "    some_data = list(path.glob(\"*/data/*.npy\"))[:5]\n",
    "    some_masks = list(path.glob(\"*/masks/*.npy\"))[:5]\n",
    "    print(\"Sample data files:\", [p.as_posix() for p in some_data])\n",
    "    print(\"Sample mask files:\", [p.as_posix() for p in some_masks])\n",
    "\n",
    "# Instantiate your dataset (assumes LungDataset and `seq` are defined)\n",
    "dataset = LungDataset(path, seq, base_seed=42)  # same idx yields same augmented result across runs\n",
    "print(\"Dataset size:\", len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IX82OeI_MuLJ"
   },
   "source": [
    "Visualize our dataset. To make sure that the augmentation works, we accessed the same element multiple times and checked whether the segmentation masks fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9q1z6HCEx1Il",
    "outputId": "6f2ed522-e018-4857-c51c-7b126218d048"
   },
   "outputs": [],
   "source": [
    "list(range(min(len(dataset), 9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 928
    },
    "id": "HuVhZYVeMiqS",
    "outputId": "0f5afcd0-16d7-4ff2-8a4f-cd6b5d82ef69"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def reorient_2d(a: np.ndarray) -> np.ndarray:\n",
    "    # flip vertically, then rotate -90° (clockwise)\n",
    "    return np.rot90(np.flipud(a), k=3)\n",
    "\n",
    "def window_hu(img, center, width):\n",
    "    lo = center - width/2.0\n",
    "    hi = center + width/2.0\n",
    "    img = np.nan_to_num(img, nan=lo, posinf=hi, neginf=lo)\n",
    "    img = np.clip(img, lo, hi)\n",
    "    return (img - lo) / (hi - lo + 1e-8)  # normalize to [0,1]\n",
    "\n",
    "# choose a preset\n",
    "WINDOWS = {\n",
    "    \"lung\":        (-600, 1500),\n",
    "    \"mediastinal\": (  40,  400),\n",
    "    \"soft_tissue\": (  50,  350),\n",
    "}\n",
    "preset = \"lung\"   # <- try \"mediastinal\" if too bright\n",
    "C, W = WINDOWS[preset]\n",
    "\n",
    "# pick first 9 indices with any labeled pixels\n",
    "idxs = []\n",
    "for i in range(len(dataset)):\n",
    "    _, m = dataset[i]               # (1,H,W)\n",
    "    if np.squeeze(m).max() > 0:     # any label present\n",
    "        idxs.append(i)\n",
    "        if len(idxs) == 9:\n",
    "            break\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(9, 9), constrained_layout=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "for k, ax in enumerate(axes):\n",
    "    ax.axis(\"off\")\n",
    "    if k >= len(idxs): continue\n",
    "\n",
    "    slc, msk = dataset[idxs[k]]     # (1,H,W)\n",
    "    img2d = np.squeeze(slc)\n",
    "    m2d   = np.squeeze(msk)\n",
    "\n",
    "    # reorient\n",
    "    img_r = reorient_2d(img2d)\n",
    "    msk_r = reorient_2d(m2d)\n",
    "\n",
    "    # window using chosen preset (darker than percentile)\n",
    "    disp = window_hu(img_r, center=C, width=W)\n",
    "\n",
    "    ax.imshow(disp, cmap=\"bone\", interpolation=\"none\")\n",
    "    if np.any(msk_r > 0):\n",
    "        ax.imshow(np.ma.masked_where(msk_r <= 0, msk_r),\n",
    "                  cmap=\"autumn\", alpha=0.40, interpolation=\"nearest\")\n",
    "    ax.set_title(f\"idx={idxs[k]} • {preset} (C={C}, W={W})\", fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asde-pKKzxAP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
