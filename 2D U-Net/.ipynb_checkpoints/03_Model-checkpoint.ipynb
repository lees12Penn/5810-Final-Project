{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKlMJHao3-9W"
   },
   "source": [
    "# Introduction\n",
    "In this notebook we created the model for the Tumor Segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "du-ebnGb4JAg"
   },
   "source": [
    "#Imports:\n",
    "\n",
    "\n",
    "1.   Torch for model creation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2e8cigQ35uP"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEBLJ3LC4VK8"
   },
   "source": [
    "## UNET\n",
    "The idea behind a UNET is that we have \"Downconvolutions\" which are reducing the size of the image combined with increasing filter size followed by \"Upconvolutions\" which increase the image size up to the original size while reducing the number of filters. <br />\n",
    "All pairs between Up- and Downconvolutions are linked with skip connections.<br />\n",
    "Upsampling can either be done by interpolation or by UpConvolutions (ConvTranspose2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ht6tLwxx4RCc",
    "outputId": "f1b4f437-aa5b-4acf-f166-6c8343ff43af"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "notebook_dir = Path(\"/content/drive/MyDrive/Colab Notebooks\")  # <-- set to the folder containing your .ipynb\n",
    "notebook_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "import os\n",
    "os.chdir(notebook_dir)  # now saves go next to the .ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "id": "WDLQ0Tk26oaD",
    "outputId": "75c0189b-4568-4ef9-9972-010bba0e5caf"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image('/content/drive/MyDrive/Colab Notebooks/unet.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KF1Agz6b78GD"
   },
   "source": [
    "# Convolutions\n",
    "At first we wrote the class, responsible for the convolutions. We use two convolutions between each down- or upconvolution step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdolymXF7oZD"
   },
   "outputs": [],
   "source": [
    "class DoubleConv(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Helper Class which implements the intermediate Convolutions\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "\n",
    "        super().__init__()\n",
    "        self.step = torch.nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "                                        torch.nn.ReLU(),\n",
    "                                        torch.nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "                                        torch.nn.ReLU())\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.step(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufI8WFRH8cIe"
   },
   "source": [
    "# U-Net\n",
    "With the help of DoubleConv we can implement the U-Net by combining DoubleConv with maxpooling for DownConvolutions or DoubleConv with Upsample for UpConv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5Da89i48RAd"
   },
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements a UNet for the Segmentation\n",
    "    We use 3 down- and 3 UpConvolutions and two Convolutions in each step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Sets up the U-Net Structure\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        ############# DOWN #####################\n",
    "        self.layer1 = DoubleConv(1, 64)  # MRI -> One channel\n",
    "        self.layer2 = DoubleConv(64, 128)\n",
    "        self.layer3 = DoubleConv(128, 256)\n",
    "        self.layer4 = DoubleConv(256, 512)\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        ############## UP #######################\n",
    "        self.layer5 = DoubleConv(512 + 256, 256)\n",
    "        self.layer6 = DoubleConv(256+128, 128)\n",
    "        self.layer7 = DoubleConv(128+64, 64)\n",
    "        self.layer8 = torch.nn.Conv2d(64, 1, 1)  # Binary label -> One class\n",
    "        #########################################\n",
    "\n",
    "        self.maxpool = torch.nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        ####### DownConv 1#########\n",
    "        x1 = self.layer1(x)\n",
    "        x1m = self.maxpool(x1)\n",
    "        ###########################\n",
    "\n",
    "        ####### DownConv 2#########\n",
    "        x2 = self.layer2(x1m)\n",
    "        x2m = self.maxpool(x2)\n",
    "        ###########################\n",
    "\n",
    "        ####### DownConv 3#########\n",
    "        x3 = self.layer3(x2m)\n",
    "        x3m = self.maxpool(x3)\n",
    "        ###########################\n",
    "\n",
    "        ##### Intermediate Layer ##\n",
    "        x4 = self.layer4(x3m)\n",
    "        ###########################\n",
    "\n",
    "        ####### UpCONV 1#########\n",
    "        x5 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x4)  # Upsample with a factor of 2\n",
    "        #x5 = torch.nn.ConvTranspose2d(512, 512, 2, 2)(x4)\n",
    "        x5 = torch.cat([x5, x3], dim=1)  # Skip-Connection\n",
    "        x5 = self.layer5(x5)\n",
    "        ###########################\n",
    "\n",
    "        ####### UpCONV 2#########\n",
    "        x6 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x5)\n",
    "        #x6 = torch.nn.ConvTranspose2d(256, 256, 2, 2)(x5)\n",
    "        x6 = torch.cat([x6, x2], dim=1)  # Skip-Connection\n",
    "        x6 = self.layer6(x6)\n",
    "        ###########################\n",
    "\n",
    "        ####### UpCONV 3#########\n",
    "        x7 = torch.nn.Upsample(scale_factor=2, mode=\"bilinear\")(x6)\n",
    "        #x7 = torch.nn.ConvTranspose2d(128, 128, 2, 2)(x6)\n",
    "        x7 = torch.cat([x7, x1], dim=1)\n",
    "        x7 = self.layer7(x7)\n",
    "        ###########################\n",
    "\n",
    "        ####### Predicted segmentation#########\n",
    "        ret = self.layer8(x7)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFnBDuOZ8-yl"
   },
   "source": [
    "#Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3X2IzsC188o8"
   },
   "outputs": [],
   "source": [
    "model = UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Czny5dB9C1R"
   },
   "outputs": [],
   "source": [
    "random_input = torch.randn(1, 1, 256, 256)\n",
    "output = model(random_input)\n",
    "assert output.shape == torch.Size([1, 1, 256, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1lILwIm9Ery"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
